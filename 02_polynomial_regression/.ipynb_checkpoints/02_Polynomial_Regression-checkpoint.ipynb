{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercise 2 - Polynomial Regression\n",
    "\n",
    "In this exercise you will learn about a new type of regression - the polynomial regression. With polynomial regression it is possible to fit a nonlinear relationship between the dependent and the independent variables, although the problem of estimating the parameters is linear and can be solved with the standard linear regression approach.\n",
    "\n",
    "The idea here is to learn a bunch of (polynomial) models on the same data set and explore the meaning of over- and underfitting the data.\n",
    "\n",
    "In a second part, we will use Leave One Out Crossvalidation to find a good regularization parameter on the Boston Housing dataset.\n",
    "\n",
    "In the event of a persistent problem, do not hesitate to contact the course instructor under\n",
    "\n",
    "- paul.kahlmeyer@uni-jena.de\n",
    "- maurice.wenig@uni-jena.de\n",
    "\n",
    "### Submission\n",
    "- Deadline of submission:\n",
    "23.04.2024 23:59\n",
    "- Submission on [moodle page](https://moodle.uni-jena.de/course/view.php?id=54249)\n",
    "\n",
    "\n",
    "### Help\n",
    "In case you cannot solve a task, you can use the saved values within the `help` directory:\n",
    "- Load arrays with [Numpy](https://numpy.org/doc/stable/reference/generated/numpy.load.html)\n",
    "```\n",
    "np.load('help/array_name.npy')\n",
    "```\n",
    "- Load functions with [Dill](https://dill.readthedocs.io/en/latest/dill.html)\n",
    "```\n",
    "import dill\n",
    "with open('help/some_func.pkl', 'rb') as f:\n",
    "    func = dill.load(f)\n",
    "```\n",
    "\n",
    "to continue working on the other tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "We now have a new dataset saved as `train.npy`.\n",
    "\n",
    "### Task 1\n",
    "Load this Dataset using the [`np.load`](https://numpy.org/doc/stable/reference/generated/numpy.load.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load train.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns of the dataset represent the variables. Let `X` be the explanatory variable in the first column and `Y` be the variable we want to predict in the second column. \n",
    "\n",
    "### Task 2\n",
    "Visualize the data with a scatterplot of `X` against `Y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: scatter plot the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression\n",
    "As you can see, the relationship between the dependent variable and the explanatory one does not seem to be linear and the standard linear regression from the lecture will not perform well. One way to account for such a non linear relationship is called [polynomial regression](https://en.wikipedia.org/wiki/Polynomial_regression). For a scalar explanatory variable `X` and a scalar dependent variable `Y`, the data generation model is:\n",
    "\n",
    "$$\n",
    "Y = \\theta_0 + \\theta_1 * X + \\theta_2 X^2 + \\dots + \\theta_d X^d  + \\epsilon = \\sum_{j=0}^d \\theta_j X^j + \\epsilon\n",
    "$$\n",
    "where $d$ is called degree. Similar to linear regression, we assume $\\varepsilon$ to be standard normal distributed noise.\n",
    "\n",
    "Although the relationship between the dependent and the explanatory variable is non linear, the problem of estimating the parameters $\\theta$ is linear. By vectorizing the model, this becomes obvious:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    Y_1 \\\\\n",
    "    Y_2 \\\\\n",
    "    \\vdots \\\\\n",
    "    Y_n\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "    \\theta_0 \\\\\n",
    "    \\theta_1 \\\\\n",
    "    \\vdots \\\\\n",
    "    \\theta_d\n",
    "\\end{bmatrix}^T\n",
    "\\begin{bmatrix}\n",
    "    1 & 1 & \\dots & 1\\\\\n",
    "    X_1 & X_2 & \\dots & X_n\\\\\n",
    "    \\vdots&\\vdots&\\vdots&\\vdots\\\\\n",
    "    X_1^d & X_2^d &\\dots & X_n^d\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "    \\epsilon_1 \\\\\n",
    "    \\epsilon_2 \\\\\n",
    "    \\vdots \\\\\n",
    "    \\epsilon_n\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This linear model can now be fit with the linear regression approach. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "Implement a function `poly` to create the design matrix for the polynomial regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.typing as npt\n",
    "\n",
    "\n",
    "def polynomial_design_matrix(x: npt.NDArray[np.float64], degree: int) -> npt.NDArray[np.float64]:\n",
    "    \"\"\"Creates the polynomial design matrix.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : npt.NDArray[np.float64]\n",
    "        Vector of scalar features.\n",
    "    degree : int\n",
    "        Maximum degree of the polynomial.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    npt.NDArray[np.float64]\n",
    "        Design matrix for polynomial regression. The rows of the design matrix are powers of the input vector x.\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: return polynomial design matrix\n",
    "    pass\n",
    "\n",
    "\n",
    "# assertion\n",
    "x_test = np.array([1, 2, 3, 5])\n",
    "target = np.array([[1, 1, 1, 1],\n",
    "                   [1, 2, 3, 5],\n",
    "                   [1, 4, 9, 25],\n",
    "                   [1, 8, 27, 125]])\n",
    "assert np.allclose(polynomial_design_matrix(x_test, 3), target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "Implement a class `PolyReg` that fits a polynomial model with ordinary least squares. Regularize your maximum-likelihood problem with ridge regression.\n",
    "\n",
    "Hint: Recycle the `LinReg` class from the last exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Self\n",
    "\n",
    "\n",
    "class PolynomialRegressor():\n",
    "    def __init__(self, degree: int, regularization_constant: int = 0):\n",
    "        \"\"\"Polynomial Regressor for 1D features.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        degree : int\n",
    "            Highest degree the fit polynomial should have.\n",
    "        regularization_constant : int, optional\n",
    "            Regularization constant for the linear regression, by default 0.\n",
    "        \"\"\"\n",
    "\n",
    "        self.degree = degree\n",
    "        self.regularization_constant = regularization_constant\n",
    "        self.theta = None\n",
    "\n",
    "    def fit(self, x: npt.NDArray[np.float64], y: npt.NDArray[np.float64]) -> Self:\n",
    "        \"\"\"Learn the parameters for a polynomial regression task.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : npt.NDArray[np.float64]\n",
    "            Vector of scalar features.\n",
    "        y : npt.NDArray[np.float64]\n",
    "            Corresponding vector of scalar labels.\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: implement\n",
    "        return self\n",
    "\n",
    "    def predict(self, x: npt.NDArray[np.float64]) -> npt.NDArray[np.float64]:\n",
    "        \"\"\"Using learned parameters, predicts output for given X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : npt.NDArray[np.float64]\n",
    "            Vector of scalar features.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        npt.NDArray[np.float64]\n",
    "            Predicted vector of scalar labels.\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: implement\n",
    "        pass\n",
    "\n",
    "\n",
    "# assertion\n",
    "np.random.seed(0)\n",
    "x_assert = np.random.rand(1000)\n",
    "y_assert = np.random.rand(1000)\n",
    "regressor = PolynomialRegressor(degree=3)\n",
    "regressor.fit(x_assert, y_assert)\n",
    "target = np.array([0.52589354, -0.199265, 0.50928455, -0.33705693])\n",
    "assert np.allclose(regressor.theta, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "Next we want to fit a series of models of multiple degrees and visualise them alongside the data.\n",
    "\n",
    "We want to use the following polynomial degrees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model degrees\n",
    "model_degrees = [0, 1, 2, 3, 6, 9, 12, 15, 18, 21]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "\n",
    "For each polynomial degree:\n",
    "1. Learn the polynomial model\n",
    "2. Plot the data \n",
    "3. Plot the regression line\n",
    "\n",
    "Plot each model in a separate [subplot](https://matplotlib.org/3.5.0/api/_as_gen/matplotlib.pyplot.subplots.html). Use a scatter plot for the data.\n",
    "\n",
    "Additionaly experiment what happens if you change the values for the regularization parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: Learn models and visualize regression lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: What effect does regularization_constant have on the regression lines?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation\n",
    "To evaluate the models, we need a measure of fit, that tells us how well the model fits the data. The standard measure for continuously distributed data is the [\"root mean squared error\" (RMSE)](https://en.wikipedia.org/wiki/Root-mean-square_deviation). Given the dependent variable $Y \\in \\mathbb{R}^n$ and its prediction $\\hat{Y} = f(X, \\theta) \\in \\mathbb{R}^n$, the RMSE is defined as:\n",
    "\n",
    "$$\n",
    "\\text{RMSE}(Y, \\hat{Y}) = \\sqrt{\\frac{1}{n} \\sum_{i}^n (Y_i - \\hat{Y}_i)^2}\n",
    "$$\n",
    "\n",
    "### Task 6\n",
    "Implement a `rmse` function that returns the RMSE of a vector of observations $Y$ and its predictions $\\hat{Y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y: npt.NDArray[np.float64], y_hat: npt.NDArray[np.float64]) -> float:\n",
    "    \"\"\"Calculates the root mean squared error (RMSE) of Y and its prediction Y_hat.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : npt.NDArray[np.float64]\n",
    "        Vector of true dependend variables.\n",
    "    y_hat : npt.NDArray[np.float64]\n",
    "        Vector of predicted dependend variables.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Root mean squared error between y and y_hat.\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: calculate RMSE\n",
    "    pass\n",
    "\n",
    "\n",
    "# assertion\n",
    "np.random.seed(0)\n",
    "y = np.random.rand(100)\n",
    "y_hat = np.random.rand(100)\n",
    "assert np.isclose(rmse(y, y_hat), 0.41628103800387234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to estimate which polynomial estimation fits best to our data.\n",
    "More complex models will in general yield better results on the data that was used to train them, but the quality of the model is determined by its \"generalizability\" (\"how well does the model perform on data that it has not seen before?\"). \n",
    "\n",
    "To evaluate this performance, we split the data in two sets:\n",
    "- trainset (`train.npy`)\n",
    "- testset (`test.npy`)\n",
    "\n",
    "where we train our predictor on the trainset and evaluate the generalizability on the testset.\n",
    "\n",
    "### Task 7\n",
    "\n",
    "Load the testset (stored as `test.npy`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: load test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8\n",
    "To estimate the quality of our models:\n",
    "- fit 20 polynomial models of degree 0 to 19 on the trainset.\n",
    "- calculate the RMSE of all the models on the trainset.\n",
    "- calculate the RMSE of all the models on the testset.\n",
    "\n",
    "Set the regularization parameter to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: calculate train- and test RMSEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9\n",
    "Now visualize the training RMSE and testing RMSE in dependence of the degree of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot RMSEs against polynomial degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the two curves of the previously generated figure you can determine the fit of the models.\n",
    "\n",
    "\n",
    "||Train RMSE|Test RMSE|\n",
    "| --- | --- | --- |\n",
    "|Underfitting|High|High|\n",
    "|Overfitting|Low|High|\n",
    "|Good|Low|Low|\n",
    "|Bad split|High|Low|\n",
    "\n",
    "### Task 10\n",
    "List briefly:\n",
    "- which models underfit\n",
    "- which models overfit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: answer"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
